{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load datasets and handle errors. \n",
    "**Main Features**\n",
    "- File type check: Ensures the file is a CSV.\n",
    "- Data loading: Attempts to read the CSV using Pandas.\n",
    "- Empty data check: Raises an error if the file or dataset is empty.\n",
    "- Separator check: Detects potential wrong separators if only one column is found.\n",
    "- Error handling: Handles common errors like file not found, empty files, parsing issues, and encoding problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(df_name, sep=','):\n",
    "\n",
    "    \"\"\"\n",
    "    Load a dataset from a CSV file, with error handling for common issues like file not found,\n",
    "    empty files, incorrect separators, and encoding problems.\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the file is a CSV\n",
    "        if not df_name.endswith('.csv'):\n",
    "            raise ValueError(\"Only CSV files are supported.\")\n",
    "        \n",
    "        # Try to load the dataset\n",
    "        df = pd.read_csv(df_name)\n",
    "        \n",
    "        # Check if the dataframe is empty\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"The dataset '{df_name}' is empty.\")\n",
    "        \n",
    "        # Check if the file was read correctly (if only 1 column, it's likely the wrong separator)\n",
    "        if len(df.columns) == 1:\n",
    "            raise ValueError(f\"The file '{df_name}' might have an incorrect separator. Currently using '{sep}'.\")\n",
    "        \n",
    "        df.columns = df.columns.str.lower()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file '{df_name}' was not found. Please check the file path.\")\n",
    "    \n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(f\"The file '{df_name}' is empty or contains only headers.\")\n",
    "    \n",
    "    except pd.errors.ParserError:\n",
    "        raise ValueError(f\"There was an error parsing the file '{df_name}'. It might be corrupted.\")\n",
    "    \n",
    "    except UnicodeDecodeError:\n",
    "        raise ValueError(f\"Failed to decode the file '{df_name}'. It might have an unsupported encoding.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"An unexpected error occurred while loading the dataset: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will need update, because I don't know how the data will be named\n",
    "shop_sales = load_dataset('./data/shop_sales.csv')\n",
    "shop_sales_dates = load_dataset('./data/shop_sales_dates.csv')\n",
    "shop_sales_prices = load_dataset('./data/shop_sales_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fill missing values in shop_sales_dataset. \n",
    "**Main Features**\n",
    "- Column type conversion: Converts date_id, item_id, store_id, and cnt to appropriate data types.\n",
    "- Handling NaN in date_id: Fills missing date_id values incrementally while checking for consecutive NaNs and raises an error if found.\n",
    "- Filling NaNs in item_id: Fills missing item_id values based on surrounding rows.\n",
    "- Filling NaNs in store_id: Uses the prefix of item_id to fill missing store_id values.\n",
    "- Final check for NaNs: Warns if any NaN values remain after filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values_shop_sales(initial_df):\n",
    "    \"\"\"\n",
    "    Fills missing values (NaNs) in the 'date_id', 'item_id', and 'store_id' columns of the dataset\n",
    "    based on specific rules provided. Also converts column types at the beginning and handles \n",
    "    consecutive NaNs in the 'date_id' column.\n",
    "\n",
    "    \"\"\"\n",
    "    df = initial_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # Convert column types\n",
    "    df['date_id'] = pd.to_numeric(df['date_id'], errors='coerce').astype(float)  # Allowing NaNs as float\n",
    "    df['item_id'] = df['item_id'].astype(str)\n",
    "    df['store_id'] = df['store_id'].astype(str)\n",
    "    df['cnt'] = pd.to_numeric(df['cnt'], errors='coerce').astype(float)\n",
    "\n",
    "    # Sort data by date_id to ensure correct sequential logic\n",
    "    # df = df.sort_values(by=['item_id']).reset_index(drop=True)\n",
    "\n",
    "    # Get the maximum date_id\n",
    "    max_date_id = df['date_id'].max() \n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        if pd.isna(df.at[i, 'date_id']):\n",
    "            # Detect consecutive NaNs in 'date_id'\n",
    "            if pd.isna(df.at[i - 1, 'date_id']):\n",
    "                raise ValueError(f\"Consecutive NaN values detected in 'date_id' at index {i}. Cannot determine the correct value.\")\n",
    "            # Handle non-consecutive NaN\n",
    "            if df.at[i - 1, 'date_id'] == max_date_id:\n",
    "                df.at[i, 'date_id'] = 1\n",
    "            else:\n",
    "                df.at[i, 'date_id'] = df.at[i - 1, 'date_id'] + 1\n",
    "\n",
    "    # Fill NaN values in 'item_id'\n",
    "    for i in range(len(df)):\n",
    "        if pd.isna(df.at[i, 'item_id']):\n",
    "            if df.at[i, 'date_id'] == 1:\n",
    "                df.at[i, 'item_id'] = df.at[i + 1, 'item_id'] if i + 1 < len(df) else df.at[i - 1, 'item_id']\n",
    "            elif df.at[i, 'date_id'] == max_date_id:\n",
    "                df.at[i, 'item_id'] = df.at[i - 1, 'item_id']\n",
    "            else:\n",
    "                df.at[i, 'item_id'] = df.at[i - 1, 'item_id']\n",
    "\n",
    "    # Fill NaN values in 'store_id' based on 'item_id'\n",
    "    for i in range(len(df)):\n",
    "        if pd.isna(df.at[i, 'store_id']):\n",
    "            df.at[i, 'store_id'] = df.at[i, 'item_id'].split('_')[0]  # Extract the prefix from item_id\n",
    "\n",
    "    # Final check if there are any remaining NaN values\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(\"Warning: Some NaN values are still present after filling.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example usage\n",
    "shop_sales.at[1, 'date_id'] = float('NaN')\n",
    "shop_sales_processed = fill_missing_values_shop_sales(shop_sales)\n",
    "shop_sales_processed.at[1, 'date_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fill missing values in shop_sales_dates_dataset\n",
    "**Main Features**\n",
    "- Column type conversion: Converts date_id, wm_yr_wk, wday, month, year, and cashback_store_* columns to appropriate numeric types, allowing NaNs where necessary.\n",
    "- Filling NaNs in date_id: Interpolates missing date_id values and sets the first and last dates manually.\n",
    "- Drop weekday column: Removes the unused weekday column from the dataset.\n",
    "- Filling NaNs in date: Fills missing date values sequentially, raising an error if consecutive NaNs are detected.\n",
    "- Extract date components: Fills missing wday, month, and year values using the date column.\n",
    "- Handle missing event data: Replaces NaNs in event_name_1, event_type_1, event_name_2, and event_type_2 with 'Unknown'.\n",
    "- Handle missing cashback values: Fills NaNs in cashback_store_1, cashback_store_2, and cashback_store_3 with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_shop_sales_dates(initial_df):\n",
    "    \"\"\"\n",
    "    Filling NaNs and converting types based on the following rules:\n",
    "    - Convert data types.\n",
    "    - Fill NaNs in 'date' and 'date_id' in the same way as 'date_id' in the previous dataset.\n",
    "    - Drop 'weekday' column.\n",
    "    - If 'wday', 'month', or 'year' is NaN, extract it from 'date'.\n",
    "    - Replace NaNs in 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2' with 'Unknown'.\n",
    "    - Fill NaNs in 'cashback_store_1', 'cashback_store_2', 'cashback_store_3' with 0.\n",
    "    \"\"\"\n",
    "    df = initial_df.reset_index(drop=True)\n",
    "    # Convert column types\n",
    "    df['date_id'] = pd.to_numeric(df['date_id'], errors='coerce')\n",
    "    df['wm_yr_wk'] = pd.to_numeric(df['wm_yr_wk'], errors='coerce').astype(int)\n",
    "    df['wday'] = pd.to_numeric(df['wday'], errors='coerce').astype(int)\n",
    "    df['month'] = pd.to_numeric(df['month'], errors='coerce').astype(int)\n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce').astype(int)\n",
    "    df['cashback_store_1'] = pd.to_numeric(df['cashback_store_1'], errors='coerce').astype(float)\n",
    "    df['cashback_store_2'] = pd.to_numeric(df['cashback_store_2'], errors='coerce').astype(float)\n",
    "    df['cashback_store_3'] = pd.to_numeric(df['cashback_store_3'], errors='coerce').astype(float)\n",
    "\n",
    "    df['date_id'] = df['date_id'].interpolate(method='linear')\n",
    "\n",
    "    df.at[0, 'date_id'] = 1\n",
    "    df.loc[df.index[-1], 'date_id'] = df['date_id'].iloc[-2] + 1\n",
    "\n",
    "    # Drop 'weekday' column\n",
    "    df = df.drop(columns=['weekday'])\n",
    "\n",
    "    if pd.isna(df.at[0, 'date']):\n",
    "        if not pd.isna(df.at[1, 'date']):\n",
    "            df.at[0, 'date'] = df.at[1, 'date'] - pd.DateOffset(days=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Consecutive NaN values detected in 'date' at index 1. Cannot determine the correct value.\")\n",
    "\n",
    "    # Fill NaNs in 'date' in the same way as 'date_id'\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    for i in range(1, len(df)):\n",
    "        if pd.isna(df.at[i, 'date']):\n",
    "            if pd.isna(df.at[i - 1, 'date']):\n",
    "                raise ValueError(f\"Consecutive NaN values detected in 'date' at index {i}. Cannot determine the correct value.\")\n",
    "            df.at[i, 'date'] = df.at[i - 1, 'date'] + pd.DateOffset(days=1)\n",
    "\n",
    "    # Fill 'wday', 'month', 'year' from 'date'\n",
    "    df['wday'] = df['wday'].fillna(df['date'].dt.dayofweek + 1)  # wday is 1-based\n",
    "    df['month'] = df['month'].fillna(df['date'].dt.month)\n",
    "    df['year'] = df['year'].fillna(df['date'].dt.year)\n",
    "\n",
    "    # Replace NaNs in event columns with 'Unknown'\n",
    "    event_cols = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    df[event_cols] = df[event_cols].fillna('Unknown')\n",
    "\n",
    "    # Fill NaNs in cashback_store columns with 0\n",
    "    cashback_cols = ['cashback_store_1', 'cashback_store_2', 'cashback_store_3']\n",
    "    df[cashback_cols] = df[cashback_cols].fillna(0)\n",
    "\n",
    "    # Final check for remaining NaN values\n",
    "    # if df.isna().sum().sum() > 0:\n",
    "    #     print(\"Warning: Some NaN values are still present after filling.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>date_id</th>\n",
       "      <th>cashback_store_1</th>\n",
       "      <th>cashback_store_2</th>\n",
       "      <th>cashback_store_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>11551</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>11551</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>MartinLutherKingDay</td>\n",
       "      <td>National</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>11551</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>11551</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>11551</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  wm_yr_wk  wday  month  year         event_name_1  \\\n",
       "0    2011-01-29     11101     1      1  2011              Unknown   \n",
       "1    2011-01-30     11101     2      1  2011              Unknown   \n",
       "2    2011-01-31     11101     3      1  2011              Unknown   \n",
       "3    2011-02-01     11101     4      2  2011              Unknown   \n",
       "4    2011-02-02     11101     5      2  2011              Unknown   \n",
       "...         ...       ...   ...    ...   ...                  ...   \n",
       "1814 2016-01-17     11551     2      1  2016              Unknown   \n",
       "1815 2016-01-18     11551     3      1  2016  MartinLutherKingDay   \n",
       "1816 2016-01-19     11551     4      1  2016              Unknown   \n",
       "1817 2016-01-20     11551     5      1  2016              Unknown   \n",
       "1818 2016-01-21     11551     6      1  2016              Unknown   \n",
       "\n",
       "     event_type_1 event_name_2 event_type_2  date_id  cashback_store_1  \\\n",
       "0         Unknown      Unknown      Unknown      1.0               0.0   \n",
       "1         Unknown      Unknown      Unknown      2.0               0.0   \n",
       "2         Unknown      Unknown      Unknown      3.0               0.0   \n",
       "3         Unknown      Unknown      Unknown      4.0               0.0   \n",
       "4         Unknown      Unknown      Unknown      5.0               1.0   \n",
       "...           ...          ...          ...      ...               ...   \n",
       "1814      Unknown      Unknown      Unknown   1815.0               0.0   \n",
       "1815     National      Unknown      Unknown   1816.0               0.0   \n",
       "1816      Unknown      Unknown      Unknown   1817.0               0.0   \n",
       "1817      Unknown      Unknown      Unknown   1818.0               0.0   \n",
       "1818      Unknown      Unknown      Unknown   1819.0               0.0   \n",
       "\n",
       "      cashback_store_2  cashback_store_3  \n",
       "0                  0.0               0.0  \n",
       "1                  0.0               0.0  \n",
       "2                  0.0               0.0  \n",
       "3                  1.0               1.0  \n",
       "4                  1.0               0.0  \n",
       "...                ...               ...  \n",
       "1814               0.0               0.0  \n",
       "1815               0.0               0.0  \n",
       "1816               0.0               0.0  \n",
       "1817               0.0               0.0  \n",
       "1818               0.0               0.0  \n",
       "\n",
       "[1819 rows x 13 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "shop_sales_dates.at[0, 'date_id'] = float('NaN')\n",
    "shop_sales_dates_processed = preprocess_shop_sales_dates(shop_sales_dates)\n",
    "shop_sales_dates_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fill missing values in shop_sales_dates_dataset\n",
    "**Main Features**\n",
    "- Filling NaNs in item_id: Populates missing item_id values based on the surrounding rows, using logic similar to previous datasets.\n",
    "- Filling NaNs in store_id: Fills missing store_id by extracting the prefix from item_id.\n",
    "- Filling wm_yr_wk values: Uses linear interpolation to fill missing wm_yr_wk values, rounding the result to the nearest integer.\n",
    "- Sorting: Sorts the dataset by item_id and wm_yr_wk to ensure proper data order.\n",
    "- Interpolating sell_price: Fills missing sell_price values using linear interpolation after sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_shop_sales_prices(initial_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the sales dataset by filling NaNs and sorting the data based on specific rules:\n",
    "    - Fill NaNs in 'item_id' and 'store_id' like in the first dataset.\n",
    "    - Fill 'wm_yr_wk' using linear interpolation and round if it's a float.\n",
    "    - Sort the DataFrame by ['item_id', 'wm_yr_wk'] and apply interpolation where needed.\n",
    "    \"\"\"\n",
    "    df = initial_df.reset_index(drop=True)\n",
    "\n",
    "    df['wm_yr_wk'] = pd.to_numeric(df['wm_yr_wk'], errors='coerce').astype(float)\n",
    "    df['sell_price'] = pd.to_numeric(df['sell_price'], errors='coerce').astype(float)\n",
    "\n",
    "    # Fill NaN values in 'item_id' as done in the first dataset\n",
    "    max_item_id = df['item_id'].max()\n",
    "    for i in range(1, len(df)):\n",
    "        if pd.isna(df.at[i, 'item_id']):\n",
    "            if df.at[i, 'wm_yr_wk'] == 1:\n",
    "                df.at[i, 'item_id'] = df.at[i + 1, 'item_id'] if i + 1 < len(df) else df.at[i - 1, 'item_id']\n",
    "            elif df.at[i, 'wm_yr_wk'] == max_item_id:\n",
    "                df.at[i, 'item_id'] = df.at[i - 1, 'item_id']\n",
    "            else:\n",
    "                df.at[i, 'item_id'] = df.at[i - 1, 'item_id']\n",
    "\n",
    "    # Fill NaN values in 'store_id' based on 'item_id'\n",
    "    for i in range(len(df)):\n",
    "        if pd.isna(df.at[i, 'store_id']):\n",
    "            df.at[i, 'store_id'] = df.at[i, 'item_id'].split('_')[0]  # Extract the prefix from item_id\n",
    "\n",
    "    # Fill 'wm_yr_wk' with linear interpolation and round\n",
    "    df['wm_yr_wk'] = df['wm_yr_wk'].interpolate(method='linear').round(0)\n",
    "\n",
    "    # Sort by 'item_id' and 'wm_yr_wk'\n",
    "    df = df.sort_values(by=['item_id', 'wm_yr_wk']).reset_index(drop=True)\n",
    "\n",
    "    # Interpolate 'sell_price' if needed after sorting\n",
    "    df['sell_price'] = df['sell_price'].interpolate(method='linear')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STORE_1</td>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>11101.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STORE_1</td>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>11102.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STORE_1</td>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>11103.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STORE_1</td>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>11104.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STORE_1</td>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>11105.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11136</th>\n",
       "      <td>STORE_3</td>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11137</th>\n",
       "      <td>STORE_3</td>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>11548.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11138</th>\n",
       "      <td>STORE_3</td>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>11549.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>STORE_3</td>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>11550.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11140</th>\n",
       "      <td>STORE_3</td>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>11551.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11141 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_id      item_id  wm_yr_wk  sell_price\n",
       "0      STORE_1  STORE_1_064   11101.0        2.54\n",
       "1      STORE_1  STORE_1_064   11102.0        2.54\n",
       "2      STORE_1  STORE_1_064   11103.0        2.54\n",
       "3      STORE_1  STORE_1_064   11104.0        2.54\n",
       "4      STORE_1  STORE_1_064   11105.0        2.54\n",
       "...        ...          ...       ...         ...\n",
       "11136  STORE_3  STORE_3_804   11547.0        1.88\n",
       "11137  STORE_3  STORE_3_804   11548.0        1.88\n",
       "11138  STORE_3  STORE_3_804   11549.0        1.88\n",
       "11139  STORE_3  STORE_3_804   11550.0        1.88\n",
       "11140  STORE_3  STORE_3_804   11551.0        1.88\n",
       "\n",
       "[11141 rows x 4 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_sales_prices.at[0, 'wm_yr_wk'] = float('NaN')\n",
    "shop_sales_prices_processed = preprocess_shop_sales_prices(shop_sales_prices)\n",
    "shop_sales_prices_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to merge datasets \n",
    "**Main Features**\n",
    "- Lowercase column names: Ensures all column names are lowercase for consistency across datasets.\n",
    "- Validation of date_id: Checks if the date_id column exists in both shop_sales and shop_sales_dates before merging.\n",
    "- Merging datasets: Merges shop_sales and shop_sales_dates on the date_id column using an outer join.\n",
    "- Create unique identifier: Generates a unique item_id_wm_yr_wk column in both datasets to facilitate price mapping.\n",
    "- Duplicate check: Verifies that there are no duplicate values in the item_id_wm_yr_wk column of the shop_sales_prices dataset.\n",
    "- Map prices: Maps the sell_price from shop_sales_prices to the merged dataset using item_id_wm_yr_wk.\n",
    "- Error handling: Catches and raises errors related to missing columns, duplicates, or other unexpected issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_merge(shop_sales, shop_sales_dates, shop_sales_prices):\n",
    "    \"\"\"\n",
    "    Merge two datasets on the 'date_id' column after ensuring both datasets contain this column,\n",
    "    create 'item_id_wm_yr_wk' columns, handle potential errors, check for duplicates,\n",
    "    and check for new NaN values in the merged DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Make column names lowercase\n",
    "        shop_sales.columns = shop_sales.columns.str.lower()\n",
    "        shop_sales_dates.columns = shop_sales_dates.columns.str.lower()\n",
    "        shop_sales_prices.columns = shop_sales_prices.columns.str.lower()\n",
    "\n",
    "        # Check if 'date_id' exists in both DataFrames\n",
    "        if 'date_id' not in shop_sales.columns:\n",
    "            raise ValueError(\"'date_id' column is missing in 'shop_sales' dataset.\")\n",
    "        if 'date_id' not in shop_sales_dates.columns:\n",
    "            raise ValueError(\"'date_id' column is missing in 'shop_sales_dates' dataset.\")\n",
    "        \n",
    "        merged_df = pd.merge(shop_sales, shop_sales_dates, how='outer', left_on='date_id', right_on='date_id')\n",
    "        \n",
    "        old_nans = shop_sales.isna().sum().sum()\n",
    "        new_nans = merged_df.isna().sum().sum()\n",
    "        if new_nans - old_nans > 0:\n",
    "            print(f\"Warning: {new_nans - old_nans} new NaN values appeared while merging shop sales and dates datasets.\")\n",
    "\n",
    "        # Create 'item_id_wm_yr_wk' in both datasets - a column with unique values\n",
    "        merged_df['item_id_wm_yr_wk'] = merged_df.item_id.astype(str) + '_' + merged_df.wm_yr_wk.astype(float).astype(str)\n",
    "        shop_sales_prices['item_id_wm_yr_wk'] = shop_sales_prices.item_id.astype(str) + '_' + shop_sales_prices.wm_yr_wk.astype(float).astype(str)\n",
    "\n",
    "        # Check for duplicates in 'item_id_wm_yr_wk' in shop_sales_prices\n",
    "        if shop_sales_prices.duplicated('item_id_wm_yr_wk').any():\n",
    "            raise ValueError(\"Duplicates found in 'item_id_wm_yr_wk' column in 'shop_sales_prices' dataset.\")\n",
    "\n",
    "        # Map prices\n",
    "        map_prices_dict = dict(tuple(zip(shop_sales_prices.item_id_wm_yr_wk, shop_sales_prices.sell_price)))\n",
    "        merged_df['sell_price'] = merged_df.item_id_wm_yr_wk.map(map_prices_dict)\n",
    "\n",
    "        old_nans = new_nans\n",
    "        new_nans = merged_df.isna().sum().sum()\n",
    "        if new_nans - old_nans > 0:\n",
    "            print(f\"Warning: {new_nans - old_nans} new NaN values appeared while mapping sell prices on merged dataset.\")\n",
    "\n",
    "        merged_df.sort_values(by=['item_id', 'date_id'], inplace=True)\n",
    "        merged_df.drop(columns=['item_id_wm_yr_wk'], inplace=True)\n",
    "\n",
    "        return merged_df\n",
    "    \n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Error in merging process: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 313920 new NaN values appeared while merging shop sales and dates datasets.\n",
      "Warning: 3920 new NaN values appeared while mapping sell prices on merged dataset.\n"
     ]
    }
   ],
   "source": [
    "#Example usage on datasets before cleaning NaNs\n",
    "merged_df = safe_merge(shop_sales, shop_sales_dates, shop_sales_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 3920 new NaN values appeared while mapping sell prices on merged dataset.\n"
     ]
    }
   ],
   "source": [
    "#Example usage on datasets after cleaning NaNs\n",
    "merged_df = safe_merge(shop_sales_processed, shop_sales_dates_processed, shop_sales_prices_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>cnt</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>cashback_store_1</th>\n",
       "      <th>cashback_store_2</th>\n",
       "      <th>cashback_store_3</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>STORE_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>STORE_1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>STORE_1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>STORE_1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>STORE_1_064</td>\n",
       "      <td>STORE_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81659</th>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>STORE_3</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>11551</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81704</th>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>STORE_3</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>11551</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>MartinLutherKingDay</td>\n",
       "      <td>National</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81749</th>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>STORE_3</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>11551</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81794</th>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>STORE_3</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>11551</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81839</th>\n",
       "      <td>STORE_3_804</td>\n",
       "      <td>STORE_3</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>11551</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81855 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           item_id store_id  date_id   cnt       date  wm_yr_wk  wday  month  \\\n",
       "30     STORE_1_064  STORE_1      1.0   0.0 2011-01-29     11101     1      1   \n",
       "75     STORE_1_064  STORE_1      2.0   1.0 2011-01-30     11101     2      1   \n",
       "120    STORE_1_064  STORE_1      3.0   0.0 2011-01-31     11101     3      1   \n",
       "165    STORE_1_064  STORE_1      4.0   0.0 2011-02-01     11101     4      2   \n",
       "210    STORE_1_064  STORE_1      5.0   0.0 2011-02-02     11101     5      2   \n",
       "...            ...      ...      ...   ...        ...       ...   ...    ...   \n",
       "81659  STORE_3_804  STORE_3   1815.0  21.0 2016-01-17     11551     2      1   \n",
       "81704  STORE_3_804  STORE_3   1816.0  28.0 2016-01-18     11551     3      1   \n",
       "81749  STORE_3_804  STORE_3   1817.0   5.0 2016-01-19     11551     4      1   \n",
       "81794  STORE_3_804  STORE_3   1818.0   8.0 2016-01-20     11551     5      1   \n",
       "81839  STORE_3_804  STORE_3   1819.0  17.0 2016-01-21     11551     6      1   \n",
       "\n",
       "       year         event_name_1 event_type_1 event_name_2 event_type_2  \\\n",
       "30     2011              Unknown      Unknown      Unknown      Unknown   \n",
       "75     2011              Unknown      Unknown      Unknown      Unknown   \n",
       "120    2011              Unknown      Unknown      Unknown      Unknown   \n",
       "165    2011              Unknown      Unknown      Unknown      Unknown   \n",
       "210    2011              Unknown      Unknown      Unknown      Unknown   \n",
       "...     ...                  ...          ...          ...          ...   \n",
       "81659  2016              Unknown      Unknown      Unknown      Unknown   \n",
       "81704  2016  MartinLutherKingDay     National      Unknown      Unknown   \n",
       "81749  2016              Unknown      Unknown      Unknown      Unknown   \n",
       "81794  2016              Unknown      Unknown      Unknown      Unknown   \n",
       "81839  2016              Unknown      Unknown      Unknown      Unknown   \n",
       "\n",
       "       cashback_store_1  cashback_store_2  cashback_store_3  sell_price  \n",
       "30                  0.0               0.0               0.0        2.54  \n",
       "75                  0.0               0.0               0.0        2.54  \n",
       "120                 0.0               0.0               0.0        2.54  \n",
       "165                 0.0               1.0               1.0        2.54  \n",
       "210                 1.0               1.0               0.0        2.54  \n",
       "...                 ...               ...               ...         ...  \n",
       "81659               0.0               0.0               0.0        1.88  \n",
       "81704               0.0               0.0               0.0        1.88  \n",
       "81749               0.0               0.0               0.0        1.88  \n",
       "81794               0.0               0.0               0.0        1.88  \n",
       "81839               0.0               0.0               0.0        1.88  \n",
       "\n",
       "[81855 rows x 17 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
